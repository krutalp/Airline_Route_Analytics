{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Airline Routes using Graph Anomaly Detection\n",
    "\n",
    "### 553.602 Research and Design in Applied Mathematics: Data Mining\n",
    "\n",
    "Team Members: Krutal Patel, Mansi Goel, Chenyu Xie, Nihaar Thakkar   \n",
    "\n",
    "Subject Area: Transportation Optimization, Transportation Science \n",
    "\n",
    "<img src=\"Images/airline.jpeg\" alt= “network” width=\"500\" height=\"250\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Goals\n",
    "1. Analyze Southwest route data and preform Exploratory Data Analysis\n",
    "2. Gather metrics and statistics over time for Node (Airport) and Edge (Route) attributes \n",
    "3. Develop a graph object of the Southwest network data for 2019\n",
    "4. Apply Graph Anomaly detection methods to detect airports and routes that are significant \n",
    "5. Construct an optimization method to assign scores to each \n",
    "6. Determine a new route model (by removing or adding airports to service or specific routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopy.distance as geodist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase I: Querying and Cleaning Data\n",
    "\n",
    "1. Database Schema\n",
    "    - Fleet Data: Information on southwest fleet: Unit Cost ($Millions USD) | Total Cost ($Millions USD) \n",
    "    - full_quarterly_data_set: southwest routes over time (we will analyze the most recent year 2019 data)\n",
    "    - Airports2: routes between two airports data, including metrics such as seats, \n",
    "\n",
    "\n",
    "2. Filtering and Cleaning Fleet_Data: \n",
    "    - obtain data for all aircraft within the Southwest Airline aircraft fleet\n",
    "\n",
    "3. Filtering and Cleaning SW_routes_2019 data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node (Airport) Attributes / Properties\n",
    "1. Airport Host City population\n",
    "2. Departure Delay probability\n",
    "3. Arrivial Delay probability\n",
    "4. Cancellation probability\n",
    "5. Airport Host City (closest metro area)\n",
    "\n",
    "#### Edge (Trip X -> Y) Attributes / Properties \n",
    "1. Airport Code Pairs\n",
    "2. Aircraft Type: Unit Cost of Aircraft, Average Age for Aircraft on service\n",
    "3. Total number of departures between these destinations\n",
    "4. No. of Cancellations between these airports\n",
    "5. Route demand: total number of passengers \n",
    "6. % of Seats filled = passengers on flight / total seats avaliable \n",
    "7. Average fuel cost for route/aircraft operation\n",
    "8. Average stock price in US 2019\n",
    "9. Distance between airports in miles\n",
    "10. Total operating expense\n",
    "11. Baseline revenue \n",
    "12. flight Duration (in min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet_data = pd.read_csv(\"Database/Fleet Data.csv\")\n",
    "# compiled data on 737 statistics for southwest fleets \n",
    "sw_737 = fleet_data.loc[fleet_data['Airline'] == 'Southwest Airlines']   # fixed sw_737 data - no changes should be applied here\n",
    "unit_cost_737 = int(sw_737['Unit Cost'].values[0][1:3])  # dataset 1\n",
    "avg_age_737 = int(sw_737['Average Age'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of Airports Serviced by Southwest Airlines in 2019 85\n",
      "['Boeing 737-700/700LR/Max 7' 'Boeing 737-800' 'Boeing B737 Max 800']\n"
     ]
    }
   ],
   "source": [
    "sw_routes = pd.read_csv(\"Database/full_quarterly_data_set.csv\")\n",
    "# focus on year 2019 for network generation \n",
    "sw_routes_2019 = sw_routes.loc[sw_routes['year'] == 2019]\n",
    "# compile statistics between the two quarters \n",
    "quarters = set(sw_routes_2019['quarter'].to_list())\n",
    "# split citypair column to origin and destination key id columns \n",
    "sw_routes_2019[['Origin_Airport_Code','Destination_Airport_Code']] = sw_routes_2019['citypair'].str.split('-',expand=True)\n",
    "# In the following code, we extract all of the unique airports serviced by southwest airlines - this will eventually produce a node table for us \n",
    "# To compute this, we extract origin and destination airport lists\n",
    "SW_all_destinations = list(set(sw_routes_2019['Origin_Airport_Code'].to_list() + sw_routes_2019['Destination_Airport_Code'].to_list()))\n",
    "print('Total no. of Airports Serviced by Southwest Airlines in 2019', len(SW_all_destinations))\n",
    "# Compile data for the citypair into a list to be able to compare/query from the other Airports2 dataset\n",
    "citypair_list = list(set(sw_routes_2019['citypair'].to_list()))\n",
    "\n",
    "# Develop the final edge (airport to airport) route data with attributes \n",
    "\n",
    "# For the first attribute--> let's combine together the aircraft fleet information: We need to determine the unqiue aircraft types that Southwest has\n",
    "list_of_unique_aircrafts_SW = np.unique(sw_routes_2019['aircraft'].to_list())\n",
    "print(list_of_unique_aircrafts_SW) # these are all 737 family aircraft so the data from above can be applied here\n",
    "sw_routes_2019['Aircraft_Unit_Cost ($ millions USD)'] = unit_cost_737\n",
    "# Second attribute to add is the avaerage age of the aircraft that is on service: For this, we will develop a metric s.t. 1/age produces a higher corresponding value.\n",
    "# This is because, older aircraft tend to me closer to retirement and thus less profitable for airliens as there is usually more mainteance that is needed\n",
    "sw_routes_2019['Aircraft_Inverse_Age 1/age (1/yrs)'] = 1/avg_age_737\n",
    "\n",
    "sw_edge_data_fin = sw_routes_2019.groupby('citypair').agg({'sum_departures_performed':'sum','sum_departures_scheduled':'sum', 'passengers':'sum', 'seats':'sum', \n",
    "    'avg_fuel_price':'mean', 'avg_stock_price':'mean', 'total_operating_expense':'sum', 'revenue':'sum', 'Aircraft_Unit_Cost ($ millions USD)':'mean', \n",
    "    'Aircraft_Inverse_Age 1/age (1/yrs)':'mean'})\n",
    "\n",
    "# Add new column attributes by apply a transformation using other column attributes, as specified \n",
    "sw_edge_data_fin['Number_of_Cancellations'] = sw_edge_data_fin['sum_departures_scheduled'] - sw_edge_data_fin['sum_departures_performed']\n",
    "sw_edge_data_fin['Proportion of Seats filled'] = sw_edge_data_fin['passengers'] / sw_edge_data_fin['seats']\n",
    "sw_edge_data_fin['Aircraft Age (yrs)'] = 1 / sw_edge_data_fin['Aircraft_Inverse_Age 1/age (1/yrs)']\n",
    "sw_edge_data_fin = sw_edge_data_fin.reset_index()\n",
    "sw_edge_data_fin[['Origin_Airport_Code','Destination_Airport_Code']] = sw_edge_data_fin.citypair.str.split('-',expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Intersected primary keys 0\n"
     ]
    }
   ],
   "source": [
    "# Read in the airports dataset  AIRPORTS2\n",
    "airports_data = pd.read_csv('Database\\Airports2.csv')\n",
    "# This dataset contains A LOT of data records about flight routes between any two destinations both within and outside the mainland United States\n",
    "# Based on the queried total flight route data from above, we must filter this dataframe so we only look at those specific routes and the corresponding information from them\n",
    "# Note, the route data we are looking at from the above dataset is 2019-based, we are compiling the data below as initial predictors and attributes \n",
    "airports_data['citypair'] = airports_data['Origin_airport'].astype(str) + '-' + airports_data['Destination_airport']\n",
    "# FIlTER this dataset to contain only the routes extracted from sw_routes_2019\n",
    "filtered_Airports_Data = airports_data[airports_data['citypair'].isin(citypair_list)]\n",
    "# Next step is to break apart the dates into date - month - year extractions\n",
    "# to do this, we first apply a data type transformation to convert col to python dateTime object\n",
    "filtered_Airports_Data['Fly_date'] =  pd.to_datetime(filtered_Airports_Data['Fly_date'], format='%m/%d/%Y')\n",
    "# pull out year from fly_date column to filter by year\n",
    "filtered_Airports_Data['year'] = pd.DatetimeIndex(filtered_Airports_Data['Fly_date']).year  # dataset 3\n",
    "\n",
    "# Apply grouby methods to combine data by unique flight routes \n",
    "filtrd_Airports_aggregated = filtered_Airports_Data.groupby('citypair').agg({'Flights':'sum', 'Distance':'max', 'Org_airport_lat':'max', \n",
    "    'Org_airport_long':'max', 'Dest_airport_lat':'max', 'Dest_airport_long':'max'  })\n",
    "\n",
    "# filter this dataset to extract overlapping airport-route-destination ids\n",
    "# Notice how there are only 294 intersection iterms in the sets: meaning we will end up with a lot of misisng data. We can cross validate \n",
    "# this by reviewing the number of citypair entries from each data\n",
    "print('No. of Intersected primary keys', len((set(airports_data['citypair'].to_list())).intersection(set(sw_edge_data_fin.index))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SJU'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Thus, we need another dataset to query the relevant datapoints\n",
    "us_airports = pd.read_csv(\"Database/us-airports.csv\")\n",
    "# remove uneccesary columns\n",
    "us_airports = us_airports.drop(labels = ['id','ident','elevation_ft','continent','country_name','iso_country','region_name', 'iso_region', 'local_region', 'keywords',\n",
    "    'local_code', 'home_link','wikipedia_link','last_updated','scheduled_service','name','gps_code','score'],axis=1)\n",
    "#us_airports.drop(labels=0,axis=0)\n",
    "us_airports = us_airports.drop(labels=0,axis=0)\n",
    "# generate origin table and unque key-value pairs from sw_routes table above\n",
    "origins = list(set(sw_edge_data_fin['Origin_Airport_Code'].to_list()))\n",
    "destinations = list(set(sw_edge_data_fin['Destination_Airport_Code'].to_list()))\n",
    "\n",
    "# us airports contains a key word patch  in iata_code  --> we will inner join the tables\n",
    "origin_airports = us_airports[us_airports['iata_code'].isin(origins)]\n",
    "origin_airports = origin_airports.rename(columns={'type': 'origin_airport_type', 'latitude_deg': 'origin_lat', \n",
    "    'longitude_deg':'origin_long','iata_code':'Origin_Airport_Code', 'municipality':'origin_city'})\n",
    "\n",
    "destination_airports = us_airports[us_airports['iata_code'].isin(destinations)]\n",
    "destination_airports = destination_airports.rename(columns={'type': 'dest_airport_type', 'latitude_deg': 'dest_lat', \n",
    "    'longitude_deg':'dest_long','iata_code':'Destination_Airport_Code','municipality':'dest_city'})\n",
    "\n",
    "# merge origin table with main edge dataset\n",
    "sw_edge_data_fin = sw_edge_data_fin.merge(origin_airports, how='left')\n",
    "\n",
    "# apply the same method on destinations dataset\n",
    "sw_edge_data_fin = sw_edge_data_fin.merge(destination_airports, how='left')\n",
    "\n",
    "\n",
    "# find the missing airport entry\n",
    "sw_edge_set = set(sw_edge_data_fin['Origin_Airport_Code'].to_list() + sw_edge_data_fin['Destination_Airport_Code'].to_list())\n",
    "len(sw_edge_set)\n",
    "airports_set = set(origin_airports['Origin_Airport_Code'].to_list())\n",
    "print(sw_edge_set - airports_set)\n",
    "# SJU contains missing data points- let's fix this by a simple lookup\n",
    "sju_index = sw_edge_data_fin.loc[sw_edge_data_fin['Origin_Airport_Code'] == 'SJU']\n",
    "## double check that the nan values only belong to iata code = 'SJU'\n",
    "df2=sw_edge_data_fin[sw_edge_data_fin.origin_lat.notnull()]\n",
    "print(len(sju_index) == len(sw_edge_data_fin) - len(sw_edge_data_fin[sw_edge_data_fin.origin_lat.notnull()]))\n",
    "# Boolean value is True.  This we can apply fillNA to replace the null values for SJU IATA code\n",
    "sw_edge_data_fin[['origin_airport_type']] = sw_edge_data_fin[['origin_airport_type']].fillna('medium_airport')\n",
    "sw_edge_data_fin[['dest_airport_type']] = sw_edge_data_fin[['dest_airport_type']].fillna('medium_airport')\n",
    "sw_edge_data_fin[['dest_city']] = sw_edge_data_fin[['dest_city']].fillna('San Juan')\n",
    "\n",
    "# edit and replace the origin long and lat coordinates \n",
    "sw_edge_data_fin[['origin_lat']] = sw_edge_data_fin[['origin_lat']].fillna('18.4395')\n",
    "sw_edge_data_fin[['origin_long']] = sw_edge_data_fin[['origin_long']].fillna('-65.9992')\n",
    "# edit and replace the destination long and lat cooordinates \n",
    "sw_edge_data_fin[['dest_lat']] = sw_edge_data_fin[['dest_lat']].fillna('18.4395')\n",
    "sw_edge_data_fin[['dest_long']] = sw_edge_data_fin[['dest_long']].fillna('-65.9992')\n",
    "sw_edge_data_fin[['origin_city']] = sw_edge_data_fin[['origin_city']].fillna('San Juan')\n",
    "\n",
    "# check if values were stored in both cases \n",
    "\n",
    "# sw_edge_data_fin.loc[sw_edge_data_fin['Destination_Airport_Code'] == 'SJU']\n",
    "# sw_edge_data_fin.loc[sw_edge_data_fin['Origin_Airport_Code'] == 'SJU']\n",
    "\n",
    "# Adding distance metrics \n",
    "# define the function call\n",
    "def distance_calc(origin_lat, origin_long, dest_lat, dest_long):\n",
    "    if origin_lat == 'nan':\n",
    "        return 0\n",
    "    else:\n",
    "        coords_1 = (origin_lat, origin_long)\n",
    "        coords_2 = (dest_lat, dest_long)\n",
    "        dist = geodist.geodesic(coords_1, coords_2).miles\n",
    "        return dist\n",
    "\n",
    "sw_edge_data_fin['Route_Distance'] = sw_edge_data_fin.apply(lambda x: distance_calc(x['origin_lat'], x['origin_long'], x['dest_lat'], x['dest_long']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to now incorporate data from us cities\n",
    "# let's take a look at the data in the US Cities file\n",
    "us_cities = pd.read_csv('Database/us_cities.csv')\n",
    "# let's drop irrelevant columns to reduce data size and to allow for a more efficient merge\n",
    "us_cities = us_cities.drop(labels = ['city_ascii','state_id','state_name','county_fips','county_name','source',\n",
    "    'incorporated', 'timezone', 'zips', 'ranking','lat','lng','id'],axis=1)\n",
    "# The us cities data should contain unique entries so we need to combine the data using group by and get unique city indentifiers\n",
    "us_cities_aggregated = us_cities.groupby('city').agg({'population':'max', 'density':'max'})\n",
    "# reset index to get numerical indices \n",
    "us_cities_aggregated = us_cities_aggregated.reset_index()\n",
    "# create copies for origin and destination cities and merge with isin function\n",
    "origin_cities = list(set(sw_edge_data_fin['origin_city'].to_list()))\n",
    "destination_cities = list(set(sw_edge_data_fin['dest_city'].to_list()))\n",
    "\n",
    "\n",
    "origin_cities_tbl = us_cities_aggregated[us_cities_aggregated['city'].isin(origin_cities)]\n",
    "origin_cities_tbl = origin_cities_tbl.rename(columns={'city': 'origin_city', 'population': 'origin_population', \n",
    "    'density':'origin_density'})\n",
    "dest_cities_tbl = us_cities_aggregated[us_cities_aggregated['city'].isin(destination_cities)]\n",
    "dest_cities_tbl = dest_cities_tbl.rename(columns={'city': 'dest_city', 'population': 'dest_population', \n",
    "    'density':'dest_density'})\n",
    "# merge all entries on left join\n",
    "sw_edge_data_fin = sw_edge_data_fin.merge(origin_cities_tbl, how='left')\n",
    "# apply the same method on destinations dataset\n",
    "sw_edge_data_fin = sw_edge_data_fin.merge(dest_cities_tbl, how='left')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Statistics for Southwest Network in 2019\n",
    "\n",
    "#### 85 Airports Serviced       \n",
    "#### 1240 Total Flight routes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citypair</th>\n",
       "      <th>sum_departures_performed</th>\n",
       "      <th>sum_departures_scheduled</th>\n",
       "      <th>passengers</th>\n",
       "      <th>seats</th>\n",
       "      <th>avg_fuel_price</th>\n",
       "      <th>avg_stock_price</th>\n",
       "      <th>total_operating_expense</th>\n",
       "      <th>revenue</th>\n",
       "      <th>Aircraft_Unit_Cost ($ millions USD)</th>\n",
       "      <th>...</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>dest_airport_type</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_long</th>\n",
       "      <th>dest_city</th>\n",
       "      <th>Route_Distance</th>\n",
       "      <th>origin_population</th>\n",
       "      <th>origin_density</th>\n",
       "      <th>dest_population</th>\n",
       "      <th>dest_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABQ-BWI</td>\n",
       "      <td>108.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13736.0</td>\n",
       "      <td>15444.0</td>\n",
       "      <td>57.427544</td>\n",
       "      <td>52.842995</td>\n",
       "      <td>9585665.0</td>\n",
       "      <td>11058</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>39.1754</td>\n",
       "      <td>-76.668297</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>1670.237770</td>\n",
       "      <td>765693.0</td>\n",
       "      <td>1155.5</td>\n",
       "      <td>2205092.0</td>\n",
       "      <td>2872.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABQ-DAL</td>\n",
       "      <td>488.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>56344.0</td>\n",
       "      <td>74104.0</td>\n",
       "      <td>56.594778</td>\n",
       "      <td>53.008226</td>\n",
       "      <td>14229909.0</td>\n",
       "      <td>16207</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>32.847099</td>\n",
       "      <td>-96.851799</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>580.226586</td>\n",
       "      <td>765693.0</td>\n",
       "      <td>1155.5</td>\n",
       "      <td>5668165.0</td>\n",
       "      <td>1522.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ-DEN</td>\n",
       "      <td>330.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>37782.0</td>\n",
       "      <td>47510.0</td>\n",
       "      <td>56.594778</td>\n",
       "      <td>53.008226</td>\n",
       "      <td>14229909.0</td>\n",
       "      <td>16207</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>39.86169815</td>\n",
       "      <td>-104.6729965</td>\n",
       "      <td>Denver</td>\n",
       "      <td>349.103284</td>\n",
       "      <td>765693.0</td>\n",
       "      <td>1155.5</td>\n",
       "      <td>2650725.0</td>\n",
       "      <td>1805.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABQ-HOU</td>\n",
       "      <td>326.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>39590.0</td>\n",
       "      <td>50650.0</td>\n",
       "      <td>56.927884</td>\n",
       "      <td>52.942134</td>\n",
       "      <td>23815574.0</td>\n",
       "      <td>27265</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>29.645399</td>\n",
       "      <td>-95.2789</td>\n",
       "      <td>Houston</td>\n",
       "      <td>759.153724</td>\n",
       "      <td>765693.0</td>\n",
       "      <td>1155.5</td>\n",
       "      <td>5650910.0</td>\n",
       "      <td>1394.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABQ-LAS</td>\n",
       "      <td>324.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>35966.0</td>\n",
       "      <td>46332.0</td>\n",
       "      <td>57.427544</td>\n",
       "      <td>52.842995</td>\n",
       "      <td>9585665.0</td>\n",
       "      <td>11058</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>36.083361</td>\n",
       "      <td>-115.151817</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>486.424110</td>\n",
       "      <td>765693.0</td>\n",
       "      <td>1155.5</td>\n",
       "      <td>2150373.0</td>\n",
       "      <td>1754.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  citypair  sum_departures_performed  sum_departures_scheduled  passengers  \\\n",
       "0  ABQ-BWI                     108.0                     110.0     13736.0   \n",
       "1  ABQ-DAL                     488.0                     504.0     56344.0   \n",
       "2  ABQ-DEN                     330.0                     337.0     37782.0   \n",
       "3  ABQ-HOU                     326.0                     335.0     39590.0   \n",
       "4  ABQ-LAS                     324.0                     333.0     35966.0   \n",
       "\n",
       "     seats  avg_fuel_price  avg_stock_price  total_operating_expense  revenue  \\\n",
       "0  15444.0       57.427544        52.842995                9585665.0    11058   \n",
       "1  74104.0       56.594778        53.008226               14229909.0    16207   \n",
       "2  47510.0       56.594778        53.008226               14229909.0    16207   \n",
       "3  50650.0       56.927884        52.942134               23815574.0    27265   \n",
       "4  46332.0       57.427544        52.842995                9585665.0    11058   \n",
       "\n",
       "   Aircraft_Unit_Cost ($ millions USD)  ...  origin_city  dest_airport_type  \\\n",
       "0                                 74.0  ...  Albuquerque      large_airport   \n",
       "1                                 74.0  ...  Albuquerque     medium_airport   \n",
       "2                                 74.0  ...  Albuquerque      large_airport   \n",
       "3                                 74.0  ...  Albuquerque     medium_airport   \n",
       "4                                 74.0  ...  Albuquerque      large_airport   \n",
       "\n",
       "      dest_lat     dest_long  dest_city Route_Distance origin_population  \\\n",
       "0      39.1754    -76.668297  Baltimore    1670.237770          765693.0   \n",
       "1    32.847099    -96.851799     Dallas     580.226586          765693.0   \n",
       "2  39.86169815  -104.6729965     Denver     349.103284          765693.0   \n",
       "3    29.645399      -95.2789    Houston     759.153724          765693.0   \n",
       "4    36.083361   -115.151817  Las Vegas     486.424110          765693.0   \n",
       "\n",
       "  origin_density dest_population dest_density  \n",
       "0         1155.5       2205092.0       2872.8  \n",
       "1         1155.5       5668165.0       1522.2  \n",
       "2         1155.5       2650725.0       1805.7  \n",
       "3         1155.5       5650910.0       1394.6  \n",
       "4         1155.5       2150373.0       1754.7  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  display the final edge table\n",
    "# save the final dataset as csv for export\n",
    "sw_edge_data_fin.to_csv('Database/FINAL_EDGE_TABLE.csv')\n",
    "sw_edge_data_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362    19393\n",
      "Name: Code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read in airline on time preformance data\n",
    "on_time_data = pd.read_csv('Database/August 2018 Nationwide.csv')\n",
    "# generate new column for the foreign key (route- origin-destination key)\n",
    "on_time_data['citypair'] = on_time_data['ORIGIN'].astype(str) + '-' + on_time_data['DEST']   # dataset 4\n",
    "# read in the dataset - DOT airline on time performance statistics\n",
    "on_time_data_carriers = pd.read_csv('Database/Air Carriers.csv')\n",
    "# extract corresponding code for southwest airlines\n",
    "sw_carrier_code = on_time_data_carriers.loc[on_time_data_carriers['Description'] == \"Southwest Airlines Co.: WN\", 'Code']\n",
    "print(sw_carrier_code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DELAY_NEW</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR_DELAY_NEW</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>citypair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>1587</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>377.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JFK-PHX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>1588</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>11618</td>\n",
       "      <td>EWR</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHX-EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>1590</td>\n",
       "      <td>11042</td>\n",
       "      <td>CLE</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLE-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>1591</td>\n",
       "      <td>14843</td>\n",
       "      <td>SJU</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>303.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SJU-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/1/2018</td>\n",
       "      <td>1593</td>\n",
       "      <td>10423</td>\n",
       "      <td>AUS</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUS-MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701347</th>\n",
       "      <td>8/31/2018</td>\n",
       "      <td>2357</td>\n",
       "      <td>14869</td>\n",
       "      <td>SLC</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SLC-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701348</th>\n",
       "      <td>8/31/2018</td>\n",
       "      <td>2358</td>\n",
       "      <td>15376</td>\n",
       "      <td>TUS</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUS-ORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701349</th>\n",
       "      <td>8/31/2018</td>\n",
       "      <td>2360</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DFW-LAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701350</th>\n",
       "      <td>8/31/2018</td>\n",
       "      <td>2361</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAX-MCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701351</th>\n",
       "      <td>8/31/2018</td>\n",
       "      <td>2362</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>11278</td>\n",
       "      <td>DCA</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>141.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIA-DCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>701352 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FL_DATE  OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID ORIGIN  \\\n",
       "0        8/1/2018               1587              12478    JFK   \n",
       "1        8/1/2018               1588              14107    PHX   \n",
       "2        8/1/2018               1590              11042    CLE   \n",
       "3        8/1/2018               1591              14843    SJU   \n",
       "4        8/1/2018               1593              10423    AUS   \n",
       "...           ...                ...                ...    ...   \n",
       "701347  8/31/2018               2357              14869    SLC   \n",
       "701348  8/31/2018               2358              15376    TUS   \n",
       "701349  8/31/2018               2360              11298    DFW   \n",
       "701350  8/31/2018               2361              12892    LAX   \n",
       "701351  8/31/2018               2362              13303    MIA   \n",
       "\n",
       "        DEST_AIRPORT_ID DEST  DEP_DELAY  DEP_DELAY_NEW  ARR_DELAY  \\\n",
       "0                 14107  PHX        9.0            9.0       44.0   \n",
       "1                 11618  EWR       29.0           29.0       53.0   \n",
       "2                 11298  DFW       -3.0            0.0       -2.0   \n",
       "3                 11298  DFW       44.0           44.0       43.0   \n",
       "4                 13303  MIA       -4.0            0.0       -2.0   \n",
       "...                 ...  ...        ...            ...        ...   \n",
       "701347            11298  DFW       -6.0            0.0      -17.0   \n",
       "701348            13930  ORD      -10.0            0.0       12.0   \n",
       "701349            12892  LAX        2.0            2.0      -14.0   \n",
       "701350            13204  MCO       -2.0            0.0       -5.0   \n",
       "701351            11278  DCA       76.0           76.0       59.0   \n",
       "\n",
       "        ARR_DELAY_NEW  CANCELLED  CRS_ELAPSED_TIME  ACTUAL_ELAPSED_TIME  \\\n",
       "0                44.0          0               342                377.0   \n",
       "1                53.0          0               285                309.0   \n",
       "2                 0.0          0               176                177.0   \n",
       "3                43.0          0               304                303.0   \n",
       "4                 0.0          0               173                175.0   \n",
       "...               ...        ...               ...                  ...   \n",
       "701347            0.0          0               161                150.0   \n",
       "701348           12.0          0               204                226.0   \n",
       "701349            0.0          0               198                182.0   \n",
       "701350            0.0          0               307                304.0   \n",
       "701351           59.0          0               158                141.0   \n",
       "\n",
       "        CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  LATE_AIRCRAFT_DELAY citypair  \n",
       "0                 9.0            0.0       35.0                  0.0  JFK-PHX  \n",
       "1                 0.0            0.0       53.0                  0.0  PHX-EWR  \n",
       "2                 NaN            NaN        NaN                  NaN  CLE-DFW  \n",
       "3                43.0            0.0        0.0                  0.0  SJU-DFW  \n",
       "4                 NaN            NaN        NaN                  NaN  AUS-MIA  \n",
       "...               ...            ...        ...                  ...      ...  \n",
       "701347            NaN            NaN        NaN                  NaN  SLC-DFW  \n",
       "701348            NaN            NaN        NaN                  NaN  TUS-ORD  \n",
       "701349            NaN            NaN        NaN                  NaN  DFW-LAX  \n",
       "701350            NaN            NaN        NaN                  NaN  LAX-MCO  \n",
       "701351           39.0            0.0        0.0                 20.0  MIA-DCA  \n",
       "\n",
       "[701352 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets first pull statistics \n",
    "# Here, we will treat delay D ~ r.v.  average \n",
    "on_time_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To DO next\n",
    "4. analyze the on time preformance dataset and gather metrics to add to edge table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41bca7667f83ecb8dd48977c4dba761ea06d4e04a5f0be9ce886797d1e1cddee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
