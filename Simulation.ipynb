{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Simulation and Modeling\n",
    "\n",
    "Goal: Given the two airline network models, we wish to simulate network traversals of each airline network:\n",
    " \n",
    "--> A hub and spoke based system\n",
    "\n",
    "--> A point-to-point based system\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import trapz\n",
    "from scipy.stats import bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the edge table \n",
    "edge_dataset = pd.read_csv(\"Database\\FINAL_EDGE_TABLE.csv\")\n",
    "on_time_data = pd.read_csv('Database\\FINAL_ON_TIME_DATA.csv')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    '''\n",
    "    Goal: Extract new edge attributes and reduce edge data table\n",
    "    Parameters:\n",
    "        df (pandas dataframe) input hub-spoke or point to point edge data\n",
    "    Return:\n",
    "        edge (pandas dataframe) cleaned output network edge data\n",
    "    '''\n",
    "    # create another column to preprocess the data and create new data table attributes\n",
    "    df['net_profit'] = ( df['revenue'] * 1000 - df['total_operating_expense'] ) * df['Proportion of Seats filled']\n",
    "    # extract route demand metric\n",
    "    df['Demand_prop'] = df['passengers'] / df['seats']\n",
    "\n",
    "\n",
    "    # drop additional columns that we wont need for simulation\n",
    "    edge = df.filter(['Demand_prop', 'net_profit','Origin_Airport_Code','Destination_Airport_Code','Proportion of Seats filled','CANCELLED','citypair'],axis=1)\n",
    "    # create a networkx graph from this edge dataset\n",
    "    G = nx.from_pandas_edgelist(df = edge, source = 'Origin_Airport_Code', target = 'Destination_Airport_Code', \n",
    "                               edge_attr = ['CANCELLED', 'net_profit','Proportion of Seats filled','citypair','Demand_prop'])\n",
    "    # convert graph to a directed graph\n",
    "    G = G.to_directed()\n",
    "    return G\n",
    "p_2_p_Graph = preprocess_data(edge_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['AUS', 'BNA', 'DEN', 'FLL', 'MCO', 'MDW', 'OAK', 'PHX', 'SAN', 'STL']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STL'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check if there are any leafs in the Graph --> this will affect our simulation so we must \n",
    "# i.e. there exists many cycles in the graph\n",
    "print([x for x in p_2_p_Graph.nodes() if p_2_p_Graph.in_degree(x)==0])\n",
    "\n",
    "print([x for x in p_2_p_Graph.nodes() if p_2_p_Graph.out_degree(x)==0])\n",
    "\n",
    "color=nx.get_edge_attributes(p_2_p_Graph,'net_profit')\n",
    "color[('EWR','PHX')]\n",
    "\n",
    "adj_nodes = list(p_2_p_Graph.neighbors('EWR'))\n",
    "demand=nx.get_edge_attributes(p_2_p_Graph,'Demand_prop')\n",
    "node_demand_probs = [demand[i] for i in list(p_2_p_Graph.edges('EWR'))] \n",
    "node_demand_probs = node_demand_probs / np.sum(node_demand_probs)\n",
    "next_ind = np.random.choice(np.arange(len(node_demand_probs)),size=1, p=node_demand_probs.astype(float))\n",
    "next_node = adj_nodes[next_ind[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_prob=nx.get_edge_attributes(p_2_p_Graph,'CANCELLED')\n",
    "code = cancel_prob[('PHX','EWR')]\n",
    "r = bernoulli.rvs(p=code, size=1)[0]\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Pnet_{adjusted} = (Revenue - Operating Expense) * Proportion of Seats Filled $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling from KDE distributions\n",
    "def random_samples(citypair,metric):\n",
    "    # Generate some example data\n",
    "    # x ~ vector of data based on the following\n",
    "    # filter data given citypair key and metric argument \n",
    "    fltrd = on_time_data.loc[on_time_data['citypair'] == citypair]\n",
    "    x = (fltrd[metric].to_list())\n",
    "    # Compute the KDE\n",
    "    kde = gaussian_kde(x, bw_method='silverman')\n",
    "    # Truncate the KDE to have support only over x > 0\n",
    "    pdf_trunc = lambda x: kde(x) * (x >= 0)\n",
    "    # Normalize the truncated PDF\n",
    "    norm = trapz(pdf_trunc(np.linspace(0, np.max(x), 1000)), dx=np.max(x)/999)\n",
    "    pdf_norm = lambda x: pdf_trunc(x) / norm\n",
    "    # Define the inverse CDF\n",
    "    x_vals = np.linspace(0, np.max(x), 1000)\n",
    "    cdf_vals = np.cumsum(pdf_norm(x_vals)) * np.max(x) / 999\n",
    "    inv_cdf = lambda y: np.interp(y, cdf_vals, x_vals)\n",
    "    # Generate random samples using inverse transform sampling\n",
    "    u = np.random.uniform(size=1)\n",
    "    sample = inv_cdf(u)\n",
    "    return sample\n",
    "\n",
    "\n",
    "# define a function to simulate a flight traversal for a sinl\n",
    "def simulate_flight_traversal(G, start_node, N):\n",
    "    '''\n",
    "    Goal: simulate the flight traversal for a single aircraft starting at a given start airport\n",
    "    Parameters:\n",
    "        G: The airline network graph (networkx graph object)\n",
    "        start_node: (string) the starting airport code\n",
    "        N: number of traversals (edges) to make in the network\n",
    "        start_node: the selected starting node for \n",
    "    Return:\n",
    "        total_delay_time_accumlated\n",
    "        total_cancellations\n",
    "        total_profit generated by this aircraft  \n",
    "    '''\n",
    "    current_node = start_node\n",
    "\n",
    "    # extract each attribute of the graph as a dict\n",
    "    profits=nx.get_edge_attributes(G,'net_profit')\n",
    "    cancel_prob=nx.get_edge_attributes(G,'CANCELLED')\n",
    "    citypair=nx.get_edge_attributes(G,'citypair')\n",
    "\n",
    "    total_profits = []\n",
    "    total_dept_delays = []\n",
    "    total_arrival_delays = []\n",
    "    number_of_cancel = 0\n",
    "\n",
    "\n",
    "    for i in range(N):\n",
    "        # get all adjacent nodes of the current node\n",
    "        adj_nodes = list(G.neighbors(current_node))\n",
    "        # randomly select a flight route given the transition probability \n",
    "        demand=nx.get_edge_attributes(p_2_p_Graph,'Demand_prop')\n",
    "        node_demand_probs = [demand[i] for i in list(p_2_p_Graph.edges(current_node))] \n",
    "        node_demand_probs = node_demand_probs / np.sum(node_demand_probs)\n",
    "        next_ind = np.random.choice(np.arange(len(node_demand_probs)),size=1, p=node_demand_probs.astype(float))\n",
    "        next_node = adj_nodes[next_ind[0]]\n",
    "\n",
    "        # calculate the profit of the flight route\n",
    "        profit = profits[(current_node,next_node)]\n",
    "        total_profits.append(profit)\n",
    "        # extract \n",
    "        # randomly simulate a delay time from the distribution\n",
    "        code = citypair[(current_node,next_node)]\n",
    "        dept_delay_time = random_samples(code,'DEP_DELAY_NEW')[0]\n",
    "        arr_delay_time = random_samples(code, 'ARR_DELAY_NEW')[0]\n",
    "        total_dept_delays.append(dept_delay_time)\n",
    "        total_arrival_delays.append(arr_delay_time)\n",
    "\n",
    "        cancel_p = cancel_prob[(current_node,next_node)]\n",
    "        # returns a bernoulli 0 or 1 value\n",
    "        r = bernoulli.rvs(p=cancel_p, size=1)[0]\n",
    "        number_of_cancel += r\n",
    "        print(next_node)\n",
    "        # move to the next node\n",
    "        current_node = next_node\n",
    "        # return the profit generated by the flight traversal\n",
    "    return np.sum(total_profits), np.sum(total_dept_delays), np.sum(total_arrival_delays), number_of_cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEN\n",
      "PIT\n",
      "DEN\n",
      "SEA\n",
      "DAL\n",
      "SMF\n",
      "STL\n",
      "SAT\n",
      "OAK\n",
      "MSP\n",
      "ATL\n",
      "DEN\n",
      "SJC\n",
      "BUR\n",
      "SMF\n",
      "LAX\n",
      "TUS\n",
      "SJC\n",
      "AUS\n",
      "OAK\n"
     ]
    }
   ],
   "source": [
    "x,y,z,c = simulate_flight_traversal(G=p_2_p_Graph, start_node='EWR', N=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
